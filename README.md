## ðŸ“– Course Syllabus (Outline)

The course covers the theoretical foundations and practical aspects of modern deep generative models, including:

### ðŸ”¹ Part 1: Foundations
- Introduction to Generative Modeling
- Probability & Statistical Review
- Basic Concepts in Deep Learning
- Likelihood-Based Learning

### ðŸ”¹ Part 2: Autoregressive Models
- Autoregressive Factorization
- PixelRNN / PixelCNN
- Masked Convolutions
- Training & Sampling Methods

### ðŸ”¹ Part 3: Variational Autoencoders (VAE)
- Latent Variable Models
- Evidence Lower Bound (ELBO)
- Reparameterization Trick
- Î²-VAE and Variants

### ðŸ”¹ Part 4: Normalizing Flow Models
- Change of Variables Formula
- NICE, RealNVP, Glow
- Invertible Neural Networks
- Density Estimation

### ðŸ”¹ Part 5: Generative Adversarial Networks (GAN)
- Minimax Optimization
- DCGAN, WGAN, WGAN-GP
- Mode Collapse
- Training Stability

### ðŸ”¹ Part 6: Energy-Based Models (EBM)
- Energy Functions
- Contrastive Divergence
- Score Matching
- Sampling with Langevin Dynamics

### ðŸ”¹ Part 7: Diffusion Models
- Denoising Diffusion Probabilistic Models
- Forward & Reverse Processes
- Score-Based Models
- Sampling Acceleration

### ðŸ”¹ Part 8: Evaluation Methods
- Log-Likelihood
- FID / IS
- Perceptual Metrics
- Model Comparison


## ðŸ“‚ Repository Structure

```text
.
â”œâ”€â”€ HW1/                 # Autoregressive Models
â”œâ”€â”€ HW2/                 # Variational Autoencoders
â”œâ”€â”€ HW3/                 # Flow Models & GANs
â”œâ”€â”€ HW4/                 # EBM & Diffusion Models
